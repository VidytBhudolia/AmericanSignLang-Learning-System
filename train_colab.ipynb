{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a638af",
   "metadata": {},
   "source": [
    "# ASL Detection Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7673b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected\")\n",
    "    print(\"Go to Runtime -> Change runtime type -> Select GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebdda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "!pip install -q ultralytics opencv-python-headless\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f56734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_dataset_path = '/content/drive/MyDrive/American Sign Language Letters.v6-raw.yolov8'\n",
    "local_dataset_path = '/content/data/American Sign Language Letters.v6-raw.yolov8'\n",
    "\n",
    "!mkdir -p /content/data\n",
    "!cp -r \"{drive_dataset_path}\" /content/data/\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify dataset\n",
    "dataset_path = Path(local_dataset_path)\n",
    "data_yaml = dataset_path / 'data.yaml'\n",
    "\n",
    "if data_yaml.exists():\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"Classes: {data_config.get('nc')}\")\n",
    "    print(f\"Names: {data_config.get('names')}\")\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = dataset_path / split / 'images'\n",
    "        if split_path.exists():\n",
    "            img_count = len(list(split_path.glob('*.jpg'))) + len(list(split_path.glob('*.png')))\n",
    "            print(f\"{split}: {img_count} images\")\n",
    "else:\n",
    "    print(\"ERROR: data.yaml not found\")\n",
    "    print(f\"Check path: {drive_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4cd348",
   "metadata": {},
   "source": [
    "Fix paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd43dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_yaml, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['path'] = str(dataset_path)\n",
    "config['train'] = 'train/images'\n",
    "config['val'] = 'valid/images'\n",
    "config['test'] = 'test/images'\n",
    "\n",
    "with open(data_yaml, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(f\"Dataset path: {config['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {'GPU' if device == '0' else 'CPU'}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "results = model.train(\n",
    "    data=str(data_yaml),\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    name='asl_detector',\n",
    "    patience=10,\n",
    "    save=True,\n",
    "    project='/content/output',\n",
    "    device=device,\n",
    "    plots=True,\n",
    "    cache=True\n",
    ")\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f3e00",
   "metadata": {},
   "source": [
    "Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = YOLO('/content/output/asl_detector/weights/best.pt')\n",
    "metrics = best_model.val(device=device)\n",
    "\n",
    "print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.3f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eed8be",
   "metadata": {},
   "source": [
    "Test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = dataset_path / 'test' / 'images'\n",
    "test_images = list(test_images_path.glob('*.jpg'))[:5]\n",
    "\n",
    "results = best_model.predict(\n",
    "    source=test_images,\n",
    "    save=True,\n",
    "    project='/content/output/predictions',\n",
    "    name='test_samples',\n",
    "    conf=0.25\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(test_images), figsize=(15, 3))\n",
    "if len(test_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    img_with_boxes = result.plot()\n",
    "    img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "    axes[idx].imshow(img_rgb)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Sample {idx+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10467b2e",
   "metadata": {},
   "source": [
    "Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c31ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "drive_output_path = '/content/drive/MyDrive/asl_model_trained'\n",
    "!mkdir -p \"{drive_output_path}\"\n",
    "!cp /content/output/asl_detector/weights/best.pt \"{drive_output_path}/asl_best.pt\"\n",
    "\n",
    "print(f\"Saved to Drive: {drive_output_path}/asl_best.pt\")\n",
    "\n",
    "files.download('/content/output/asl_detector/weights/best.pt')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
